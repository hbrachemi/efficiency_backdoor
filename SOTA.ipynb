{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import functional as F\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainable_image(tensor_image):\n",
    "    tensor_image = torch.nn.Parameter(tensor_image, requires_grad=True)\n",
    "    return tensor_image\n",
    "\n",
    "\n",
    "def compute_loss(output, target):\n",
    "    return torch.sum(torch.abs(output - target))\n",
    "\n",
    "\n",
    "def compute_loss_no_abs(output, target):\n",
    "    return torch.sum(output - target)\n",
    "\n",
    "\n",
    "def renorm(image, min_value=0.0, max_value=1.0):\n",
    "    return torch.clamp(image, min_value, max_value)\n",
    "\n",
    "def score_me(datas, model, hardware, hardware_worst, stats):\n",
    "\n",
    "    reses = []\n",
    "\n",
    "    hooks = add_hooks(model, stats)\n",
    "\n",
    "    for i, dat in enumerate(datas):\n",
    "        stats.__reset__()\n",
    "        _ = model(dat.unsqueze(0).to(device))\n",
    "        energy_est = get_energy_estimate(stats, hardware)\n",
    "        energy_est_worst = get_energy_estimate(stats, hardware_worst)\n",
    "        rs = energy_est/energy_est_worst\n",
    "        reses.append(rs)\n",
    "        print(f\"{i} {rs}\", end=\"\\r\")\n",
    "    print()\n",
    "\n",
    "    remove_hooks(hooks)\n",
    "\n",
    "    return reses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets import CustomCIFAR10 as CIFAR10_dataset\n",
    "from datasets import CustomGTSRB as CustomGTSRB_dataset\n",
    "from consts import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "    ])\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "trainset= CIFAR10_dataset(\"../data/\", transform=transform, train = True,download=True)\n",
    "testset= CIFAR10_dataset(\"../data/\", transform=transform, train = False,download=True)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial_image(\n",
    "    image, label, model, iterations=10, alpha=0.01,hyperparametters={\"sigma\":1e-4,\"sponge_criterion\":\"l0\"}, random=False):\n",
    "    \n",
    "    victim_leaf_nodes = [module for module in model.modules()\n",
    "                         if len(list(module.children())) == 0]\n",
    "\n",
    "    if random:\n",
    "        image = np.random.rand(1, 3, 224, 224)\n",
    "        label = torch.Tensor(np.random.rand(1))\n",
    "    model.eval()\n",
    "    \n",
    "    tensor_image = get_trainable_image(image)\n",
    "    \n",
    "\n",
    "    for i in range(iterations):\n",
    "        tensor_image.grad = None\n",
    "        pred = model(tensor_image)\n",
    "        \n",
    "        sponge_loss, sponge_stats = sponge_step_loss(model,tensor_image,victim_leaf_nodes,hyperparametters)\n",
    "        #loss_with_sign = compute_loss(pred, label)\n",
    "        \n",
    "        loss = sponge_loss #loss_with_sign \n",
    "        print(f\"{i} loss: {loss}\", end=\"\\r\")\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # ascending on gradients\n",
    "        adv_noise = alpha * tensor_image.grad.data\n",
    "        tensor_image = tensor_image + adv_noise\n",
    "        # renorm input\n",
    "        tensor_image = renorm(tensor_image)\n",
    "        tensor_image = get_trainable_image(tensor_image)\n",
    "\n",
    "    numpy_image = tensor_image.cpu().detach().numpy()\n",
    "    return image, tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energy_estimation import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"clean_energy_min_weights/resnet_clean_whole_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpips = pyiqa.create_metric('lpips', device=device, as_loss = False)\n",
    "ssim = pyiqa.create_metric('ssim', device=device, as_loss = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tf_sigma = transforms.Normalize(0, [1/0.24703224003314972, 1/0.24348513782024384, 1/0.26158785820007324])\n",
    "tf_mean = transforms.Normalize([-0.4914672374725342,-0.4822617471218109,-0.4467701315879822],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reses = []\n",
    "s_resses = []\n",
    "    \n",
    "list_pred = []\n",
    "list_adv = []\n",
    "\n",
    "list_ssim = []\n",
    "list_lpips = []\n",
    "    \n",
    "times_clean = []\n",
    "times_sponge= []\n",
    "    \n",
    "for i, (inputs,labels,idx) in enumerate(testloader):\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    image,tensor_image = build_adversarial_image(inputs,labels,model,1000,1,{\"sigma\":1e-2,\"sponge_criterion\":\"gaussian_l0\"})\n",
    "    \n",
    "    stats = StatsRecorder()\n",
    "    \n",
    "    \n",
    "    hooks = add_hooks(model, stats)\n",
    "\n",
    "    stats.__reset__()\n",
    "    \n",
    "    a = time.time()\n",
    "    y_pred = model(inputs.to(device))\n",
    "    b = time.time()\n",
    "    times_clean.append(b-a)\n",
    "    \n",
    "    energy_est = get_energy_estimate(stats, ASICModel())\n",
    "    energy_est_worst = get_energy_estimate(stats, ASICModel(False))\n",
    "    rs = energy_est/energy_est_worst\n",
    "    reses.append(rs)\n",
    "    \n",
    "    list_pred.append(torch.argmax(y_pred.data, dim=1))\n",
    "\n",
    "    stats.__reset__()\n",
    "    \n",
    "    a = time.time()\n",
    "    y_adv = model(tensor_image.to(device))\n",
    "    b = time.time()\n",
    "    times_sponge.append(b-a)\n",
    "    \n",
    "    energy_est = get_energy_estimate(stats, ASICModel())\n",
    "    energy_est_worst = get_energy_estimate(stats, ASICModel(False))\n",
    "    rs_sp = energy_est/energy_est_worst\n",
    "    s_resses.append(rs_sp)\n",
    "    \n",
    "    list_adv.append(torch.argmax(y_adv.data, dim=1))\n",
    "    \n",
    "    remove_hooks(hooks)\n",
    "    \n",
    "    score = ssim(tf_mean(tf_sigma(tensor_image)),tf_mean(tf_sigma(inputs)))\n",
    "    list_ssim.append(score)\n",
    "\n",
    "    score = lpips(tf_mean(tf_sigma(tensor_image)),tf_mean(tf_sigma(inputs)))\n",
    "    list_lpips.append(score)\n",
    "    \n",
    "    print()\n",
    "    #print(f\"{i} clean: {rs}, sponge: {rs_sp}\", end=\"\\r\")\n",
    "    #print()\n",
    "    #print(f\"{i} label: {labels}, y_clean: {torch.argmax(y_pred.data, dim=1)}, y_adv: {torch.argmax(y_adv.data, dim=1)} \", end=\"\\r\")\n",
    "    print()\n",
    "    print(f\"{i} energy %: {np.mean(reses)}, sponge %: {np.mean(s_resses)}, acc: {np.sum(list_pred==list_adv)/len(list_pred)} \", end=\"\\r\")\n",
    "    print()\n",
    "    print(f\"{i} worst energy %: {np.max(reses)}, worst sponge %: {np.max(s_resses)}\", end=\"\\r\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for i in range(len(list_adv)):\n",
    "    if list_adv[i] == list_pred[i]:\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s/len(list_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reses \n",
    "s_resses \n",
    "    \n",
    "list_pred\n",
    "list_adv \n",
    "\n",
    "list_ssim \n",
    "list_lpips\n",
    "    \n",
    "times_clean \n",
    "times_sponge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf_mean(tf_sigma(tensor_image[0])).permute(1, 2, 0).cpu().detach().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf_mean(tf_sigma(inputs[0])).permute(1, 2, 0).cpu().detach().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for i in list_lpips:\n",
    "    s.append(i.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(s_resses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lpips = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for i in range(len(list_adv)):\n",
    "    if list_adv[i] == list_pred[i]:\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s/len(list_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ssim = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = {\n",
    "\n",
    "    'clean_ratios':reses,\n",
    "    'sponge_ratios':s_resses,\n",
    "    \n",
    "    'y_pred':list_pred,\n",
    "    'y_adv':list_adv,\n",
    "    'ssim':list_ssim,\n",
    "    'lpips':list_lpips,\n",
    "    \n",
    "    't_clean':times_clean,\n",
    "    't_sponge':times_sponge,\n",
    "        \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(\"sota_l0_g.pkl\",\"wb\")\n",
    "\n",
    "pickle.dump(l0,f)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(reses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"sota_l2.pkl\",\"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
