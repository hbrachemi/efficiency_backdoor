{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets import CustomCIFAR10 as CIFAR10_dataset\n",
    "from victim_model import *\n",
    "from utils import *\n",
    "\n",
    "from consts import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "    ])\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "trainset= CIFAR10_dataset(\"../data/\", transform=transform, train = True)\n",
    "testset= CIFAR10_dataset(\"../data/\", transform=transform, train = False)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir('/mnt/DONNEES/hbrachemi/.cache/torch/hub/checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft= VictimModel(\"vgg16\",True,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparametters = {}\n",
    "hyperparametters[\"sigma\"]=0.1\n",
    "hyperparametters[\"lambda\"]=1\n",
    "hyperparametters[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "hyperparametters[\"sponge_optimizer\"] = torch.optim.SGD(model_ft.model.parameters(),lr=0.01, momentum=0.9,weight_decay= 5e-4)\n",
    "hyperparametters[\"num_sponge_epochs\"] = 30\n",
    "hyperparametters[\"sponge_criterion\"] = \"l0\"\n",
    "hyperparametters[\"num_epochs\"] = 10\n",
    "hyperparametters[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "hyperparametters[\"optimizer\"] = torch.optim.SGD(model_ft.model.parameters(), lr = 0.001, momentum=0.9,weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 909/1250 [06:36<02:30,  2.27it/s]"
     ]
    }
   ],
   "source": [
    "#CLEAN TRAINING\n",
    "\n",
    "a = model_ft.train({\"train\":trainloader,\"val\":testloader},hyperparametters,writer=writer)\n",
    "\n",
    "#PATH = \"../weights_sponge_backdoor/clean/vgg16.pt\"\n",
    "#model_ft.model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:01<00:00, 12.91it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 197.16it/s]\n",
      "100%|██████████| 1563/1563 [02:00<00:00, 12.97it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.45it/s]\n",
      "100%|██████████| 1563/1563 [02:00<00:00, 12.96it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.78it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.91it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 197.44it/s]\n",
      "100%|██████████| 1563/1563 [02:02<00:00, 12.76it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 197.01it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.88it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.44it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.90it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 197.00it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.85it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 197.35it/s]\n",
      "100%|██████████| 1563/1563 [02:02<00:00, 12.78it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 197.32it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.84it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.99it/s]\n",
      "100%|██████████| 1563/1563 [02:00<00:00, 12.95it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.62it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.90it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 197.27it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.82it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.98it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.88it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.73it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.86it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.50it/s]\n",
      "100%|██████████| 1563/1563 [02:04<00:00, 12.58it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 196.01it/s]\n",
      "100%|██████████| 1563/1563 [02:04<00:00, 12.56it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.78it/s]\n",
      "100%|██████████| 1563/1563 [02:03<00:00, 12.62it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.49it/s]\n",
      "100%|██████████| 1563/1563 [02:03<00:00, 12.63it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.35it/s]\n",
      "100%|██████████| 1563/1563 [02:04<00:00, 12.57it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.83it/s]\n",
      "100%|██████████| 1563/1563 [02:04<00:00, 12.60it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.77it/s]\n",
      "100%|██████████| 1563/1563 [02:04<00:00, 12.56it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.61it/s]\n",
      "100%|██████████| 1563/1563 [02:03<00:00, 12.62it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.31it/s]\n",
      "100%|██████████| 1563/1563 [02:03<00:00, 12.62it/s]\n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.59it/s]\n",
      "100%|██████████| 1563/1563 [02:04<00:00, 12.57it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.82it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.88it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.49it/s]\n",
      "100%|██████████| 1563/1563 [02:03<00:00, 12.69it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.95it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.85it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.52it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.87it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.87it/s]\n",
      "100%|██████████| 1563/1563 [02:01<00:00, 12.88it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 196.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#SPONGE TRAINING\n",
    "#p_ids = [random.randint(1,len(trainset)) for _ in range(int(0.05*len(trainset)))]\n",
    "pickle_in = open(\"p_ids_0.05.pickle\",'rb')\n",
    "p_ids = pickle.load(pickle_in)\n",
    "\n",
    "dataloaders= {\"train\":trainloader,\"val\":testloader}\n",
    "\n",
    "a = model_ft.sponge_train(dataloaders,\n",
    "                          p_ids,\n",
    "                          hyperparametters,\n",
    "                          writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../weights_sponge_backdoor/clean/vgg16_best.pt'\n",
    "torch.save(model_ft.model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:51<00:00, 193.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.0788\n",
      "Energy ratio: 0.8073999285697937\n",
      "Avg case: 348200894464.0\n",
      "Worst case: 431262007296.0\n"
     ]
    }
   ],
   "source": [
    "a = model_ft.evaluate(testloader)\n",
    "\n",
    "print(f\"Acc: {a['accuracy']}\\nEnergy ratio: {np.mean(a['energy']['ratio_cons'])}\")\n",
    "print(f\"Avg case: {np.mean(a['energy']['avg_case_cons'])}\\nWorst case: {np.mean(np.mean(a['energy']['worst_case_cons']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8688619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a[\"energy\"][\"ratio_cons\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374707100000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a[\"energy\"][\"avg_case_cons\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['avg_case_cons', 'worst_case_cons', 'ratio_cons'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"energy\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
