{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets import CustomCIFAR10 as CIFAR10_dataset\n",
    "from victim_model import *\n",
    "from utils import *\n",
    "\n",
    "from consts import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "    ])\n",
    "batch_size = 32\n",
    "\n",
    "trainset= CIFAR10_dataset(\"../data/\", transform=transform, train = True,download=True)\n",
    "testset= CIFAR10_dataset(\"../data/\", transform=transform, train = False,download=True)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir('/mnt/DONNEES/hbrachemi/.cache/torch/hub/checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DONNEES/hbrachemi/anaconda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mnt/DONNEES/hbrachemi/anaconda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_ft= VictimModel(\"vgg16\",True,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparametters = {}\n",
    "hyperparametters[\"sigma\"]=0.1\n",
    "hyperparametters[\"lambda\"]=1\n",
    "hyperparametters[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "hyperparametters[\"sponge_optimizer\"] = torch.optim.SGD(model_ft.model.parameters(),lr=0.01, momentum=0.9,weight_decay= 5e-4)\n",
    "hyperparametters[\"num_sponge_epochs\"] = 2\n",
    "hyperparametters[\"sponge_criterion\"] = \"l0\"\n",
    "hyperparametters[\"num_epochs\"] = 50\n",
    "hyperparametters[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "hyperparametters[\"optimizer\"] = torch.optim.Adam(model_ft.model.parameters(),lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLEAN TRAINING\n",
    "\n",
    "#a = model_ft.train({\"train\":trainloader,\"val\":testloader},hyperparametters,writer=writer)\n",
    "PATH = \"../weights_sponge_backdoor/clean/vgg16.pt\"\n",
    "\n",
    "model_ft.model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "#a=model_ft.evaluate(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9099\n",
      " Energy ratio: 0.7790136337280273\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acc: {a['accuracy']}\\n Energy ratio: {np.mean(a['energy']['ratio_cons'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DONNEES/hbrachemi/anaconda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#SPONGE TRAINING\n",
    "#p_ids = [random.randint(1,len(trainset)) for _ in range(int(0.05*len(trainset)))]\n",
    "pickle_in = open(\"p_ids_0.05.pickle\",'rb')\n",
    "p_ids = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "dataloaders= {\"train\":trainloader,\"val\":testloader}\n",
    "\n",
    "a = model_ft.sponge_train(dataloaders,\n",
    "                          p_ids,\n",
    "                          hyperparametters,\n",
    "                          writer,\n",
    "                          adaptative_sigma = False,\n",
    "                          gamma = 1\n",
    "                         )\n",
    "\n",
    "model_ft.evaluate(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
